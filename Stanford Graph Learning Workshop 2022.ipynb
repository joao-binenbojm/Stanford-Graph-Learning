{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eabeaec",
   "metadata": {},
   "source": [
    "# Stanford Graph Learning Workshop 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ec9f0",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Given a graph structure, when we want to make a prediction at a given node, the network needs to account for the graph data/representation such as connectivity. They depend on message passing and aggregation algorithms.\n",
    "\n",
    "Views:\n",
    "- GNNs learn to combine features from neighbouring nodes\n",
    "- GNNs learn the graph patterns and relations\n",
    "\n",
    "Benefits:\n",
    "- Adapt to the shape of the data\n",
    "\n",
    "CNNs/transformers are a specific application of GNNs!\n",
    "\n",
    "Use-cases:\n",
    "- Drug discovery, recommender systems, \n",
    "\n",
    "This is one of the hottest ML topics right now (top 4 keyword in ICLR 2022).\n",
    "\n",
    "Example:\n",
    "- Financial networks: describe financial entities and their relations\n",
    "- Tasks: fraud detection, anomaly detection, credit scores, etc\n",
    "\n",
    "We can identifiy at the node, graph and edge levels. Their algorithms helped a small European country identify transaction patterns over time.\n",
    "\n",
    "#### ROLAND: Tool for dynamic graphs\n",
    "- Provides scalable and adaptive training for high accuracy models\n",
    "- Built on top of PyG GraphGym\n",
    "- PyG: open-source GNN library that provides state-of-the-art Graph Representation Learning\n",
    "- pyg-lib: a low-level GNN engine to accelerate PyG\n",
    "- Most widely used framework for GNNs\n",
    "- Dedicated sparsity-aware CUDA kernels (for higher performance)\n",
    "\n",
    "PyG is used all the way from research to large companies in industry. There are also many Graph ML Tutorials and courses by Stanford. We can reach them through their Slack channel.\n",
    "- Course: http://web.stanford.edu/class/cs224w/\n",
    "- Tutorials: https://medium.com/stanford-cs224w\n",
    "\n",
    "#### Scaling-up Graph Learning\n",
    "- Came up with concept of a _Graph Store_ and _Feature Store_ to make graph storage more efficient\n",
    "- Partnered with NVIDIA (GPUs) and Intel (CPUs) for further speed increases\n",
    "\n",
    "They are also releasing a few Graph Data Benchmarks: datasets to compare different GNN structures and to understand performance.\n",
    "\n",
    "#### Knowledge Graphs\n",
    "A way to capture human knowledge in a machine-understandable form. Can range from common-sense to industry knowledge. They have worked on predicting a node that might target two other nodes. In collaboration with Google, they have increased computing to compute large-scale knowledge graphs.\n",
    "- Framework: SMORE --> scalable framework for multi-hop knowledge tasks\n",
    "- Knowledge graphs can provide additional supervision to language models created (such as reasoning, unstructred information)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87df40",
   "metadata": {},
   "source": [
    "## What's new in PyG\n",
    "__Author__: Matthias Fey\n",
    "\n",
    "Neural message passing schemes:\n",
    "- Data-dependent computation graphs\n",
    "- Generalization of any neural network to GNNs\n",
    "- GNNs are very challenging and general\n",
    "\n",
    "Graphs are typically sparse and irregular, which makes them tricky to implement. They can also describe numerical, categorical, and many other types of data simultaneously! Graphs may change over time. We may want to learn one large graph, or many small graphs. We also want to be applicable to various tasks.\n",
    "\n",
    "PyG was created on top of PyTorch to unify all these different requirements. Build on 4 main principles.\n",
    "- Graph-based neural network building blocks\n",
    "- In-memory graph storage, datasets & loaders (supports graphs with various data types)\n",
    "- Provides graph transformations & augmentations (e.g. graph diffusion, missing feature value imputation, etc)\n",
    "- Have prepared various examples & tutorials to learn more about GNNs with videos and blogs!!\n",
    "\n",
    "To use:\n",
    "- First define a dataset\n",
    "- Then like in PyTorch, create a dataLoader\n",
    "- Create a normal PyTorch module, but you can now use your own GNN layers! (SAGE)\n",
    "- Train \n",
    "\n",
    "#### PyG Progress/Evolution\n",
    "- Open-source in 2017\n",
    "- Released a paper based on this in 2019\n",
    "- Began collaborating with OGB\n",
    "- Last year, introduced Stanford Partnership\n",
    "- Next released will come in Novemeber and aims to improve acceleration and scalability\n",
    "\n",
    "#### Announcements\n",
    "- Major architecture change: a new GNN engine\n",
    "- New optimizations: Principled aggegations and improved scalability\n",
    "- pyg-lib: a unified GNN engine for optimized low-level graph routines\n",
    "\n",
    "#### Accelerating Heterogeneous GNNs\n",
    "- HeteroData: in-memory storage\n",
    "- Heterogeneous graph samplers\n",
    "- Heterogeneous GNN layers\n",
    "- to_hetero() is powerful, but lacks parallelism across node/edge types\n",
    "- pyg-lib supports parallel type-dependent transformatons via NVIDIA CUTLASS integration\n",
    "\n",
    "#### Principled Aggregations\n",
    "- Choosing the neighbourhood aggregation is a central topic in Graph ML\n",
    "    - mean-distribution: global features\n",
    "- We have seen an adaptable SoftMax aggregator that can act as both: Deeper-GCN paper\n",
    "- Aggregations are a first-class principle in PyG\n",
    "    - All aggregations are a first-class principle\n",
    "   \n",
    "- PyG now also simplifies the implementation of scalable link prediction tasks\n",
    "- PyG aim to support any backend by providing FeatureStore and GraphStore abstractions\n",
    "- \"in-memory\": storage is on the main memory of the computer\n",
    "- \"in-memory\": database\n",
    "- \"single-node in-memory\"-->\n",
    "\n",
    "- __Captum__: Enables prediction explainability for any GNN models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee1335",
   "metadata": {},
   "source": [
    "## Building PyG Open Source Community\n",
    "__Author__: Ivaylo Bahtchevanov (product manager of PyG)\n",
    "\n",
    "- PyG has recently been gaining lots of popularity across research and industry!\n",
    "- Common use-cases:\n",
    "    - Financial transactions (model interactions between entities)\n",
    "    - Fraud and risk detection using anomaly/outlier detection\n",
    "    - Validate smart contracts on existing blockchain\n",
    "- Security\n",
    "    - Identify compromised systems\n",
    "- Recommenders\n",
    "- Know-your customers\n",
    "- Drug discovery\n",
    "\n",
    "- Various libraries have been developed based on PyG\n",
    "- e.g. PyTorch Geometric Temporal (signals that vary across space and time)\n",
    "- Quiver\n",
    "- PyTorch Geometric Signed Directed\n",
    "- PyGod: Outlier detection\n",
    "- Graphein: Protein and RNA sequences\n",
    "- GraphFramEx --> Systematic performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60305e0a",
   "metadata": {},
   "source": [
    "## Kumo.ai â€“ Scaling-up PyG\n",
    "__Author__: Manan Shah & Dong Wang\n",
    "\n",
    "- Will introduce GraphStores\n",
    "- Then will talk about how Kumo has leveraged this\n",
    "\n",
    "#### Graph Learning:\n",
    "- Graphs (edges and nodes) contain features (tensors)\n",
    "- Message passing performs scatter/gather on features between node space and edge space\n",
    "- Scaling to data larger than GPU VRMA requires training on sampled subgraphs instead of the entire graph\n",
    "- Adds stochasticity but reduces GPU memory requirements to those of the sampled subgraphs\n",
    "- Data parallelsim requires replicating the graph and features in each compute node\n",
    "- Scalability: only processing sampled subgraphs\n",
    "\n",
    "- Independent scale-out: no longer constrained to single-node, in-memory datasets\n",
    "- Feature store: contains features of different nodes\n",
    "- Graph store: contains the graph structure supports efficient sampling\n",
    "- Sampler: operates on a graph store to sample a subgraph from root nodes and related parameters\n",
    "- Data Loader: Lives on the compute node, fetches samples fom graph store through sampler\n",
    "\n",
    "- Putting it all together (new version):\n",
    "    - Looks very similar to previous version\n",
    "    - Adding features to a custom feature store is easy, just define the store, and let PyG handle the syntactic sugar\n",
    "    - Adding edges is simple: specific the edge tensor, type and layout, and the custom graph stores implementation\n",
    "- Summary: they make their remote distributed computing act very similarly to how we would do single-node computing\n",
    "    - Be sure to monitor throughputs of feature fetching, sampling and other bottlenecks\n",
    "\n",
    "- How Kumo.ai build large graphs at scale\n",
    "    - In memory graph store needs a very large amount of memory\n",
    "\n",
    "- __Alternative to PyG: DGL__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac211a7",
   "metadata": {},
   "source": [
    "## Podcast Recommendations with GNNs (Spotify)\n",
    "__Author__: Andreas Damianou\n",
    "\n",
    "- Recommendation system: User features and product features and connecting users to products\n",
    "- GNNs enable explicit use of the graph structure present in these interactions\n",
    "- Combined graph: bringing together heterogeneous knowledge from different parts of the platform!\n",
    "    - Holistic representations of users and content\n",
    "- They deal with heterogeneous graphs!\n",
    "- Graph design:\n",
    "    - Semi-automated vs. hand-crafted?\n",
    "    - Focus on entities (KG approach) or consumption patterns (RecSys approach)\n",
    "- Their approach:\n",
    "    - First generate possible node candidates\n",
    "    - Second, rank possible candidates --> Chooses features for podcasts and users\n",
    "    - Finally the model can be calibrated --> \n",
    "- Predictions: Networks learn a __embedding space__, where NN is used to pick a suggestion based on a query\n",
    "- Need to capture both collaborative filtering and representation learning effects!\n",
    "- Often better to enhance rather than replace production recommender system (serve embeddings over link predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ff544",
   "metadata": {},
   "source": [
    "## Enabling Enterprises to Query the Future using PyG\n",
    "__Authors:__ Hema Raghavan & Tin-Yun Ho, Kumo.ai\n",
    "\n",
    "- ML Lifecycle:\n",
    "    - Input data cleaning, curation\n",
    "    - Target label engineering\n",
    "    - Feature engineering\n",
    "    - Architecture & Hyperparameter search\n",
    "    - ML Ops\n",
    "    \n",
    "- Machine leaning productivity is a bottleneck\n",
    "- Finding new high ROI problems: where to mine for gold!\n",
    "- Most data in enterprises are not text or images, but graph-based!\n",
    "- There is a publicly available Kaggle dataset on H&M meta-data (unstructured)\n",
    "- Kumo platform: predictive querying --> Data cleaning and curation\n",
    "    - E.g. Predict customers that have customers that haven't had transactions in 60 days, to find which ones won't make any more transactions in the next 30 days, predict which of these are least likely to churn\n",
    "- Kumo seems like a really interesting product!\n",
    "    - They don't need their input dataset to be in a 'training' table!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333c11d",
   "metadata": {},
   "source": [
    "## Graph AI to Enable Precision Medicine\n",
    "__Author:__ Marina Zitnik (Broad Institute)\n",
    "\n",
    "Applications: diagnostics and treatment!\n",
    "- $>$ 7000 rare diseases in the US alone\n",
    "- Patients with these diseases: very different phenotypes and clinicians may have never seen a patient like this\n",
    "- Diagnostic delay is pervasive and leads to problems for patients\n",
    "- SHEPHERD is few-shot learning AI for multi-faceted diagnosis of patients with rare diseases\n",
    "- Base-model: self-supervised pre-training to embed a biomedical KG\n",
    "- Individual patient information is overlaid on the KG!\n",
    "- SHEPHERD is trained on a cohort of simulated patients, and was evaluated on two external patient cohorts\n",
    "- For 70% of patients, we would not have been able to classify them based on their disease phenotypes!\n",
    "- Allows us to query knowledge graph learn to find out more about the disease\n",
    "- Graphs: necessary, not only beneficial!\n",
    "\n",
    "- The way of thinking about disease/drugs:\n",
    "    - Disease == perturbation in normal functioning of individual\n",
    "    - Find medicine that will remove perturbation\n",
    "- Networks could be used to repurpose drugs!\n",
    "    - In fact, there are direct target drugs, that directly target the cause of issue\n",
    "    - Network-based drugs: cause a cascade of reactions that treat the underlying condition!\n",
    "- All their datasets are publicly available on their website!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383bddee",
   "metadata": {},
   "source": [
    "## Challenges and Solutions in Applying Graph Neural Networks at Google\n",
    "__Author:__ Bryan Perozzi\n",
    "\n",
    "- Research scientist at Google\n",
    "- One of the pioneers of graph embeddings work\n",
    "- Co-authored work on DeepWalks (took word2vec to graphs)\n",
    "- Started with PageRank, now they're trying to use ML with the sheer volume of data they have!\n",
    "- He's the head of the GNN team\n",
    "- Big graphs are very complex and aren't homphilus (connections don't necessarily mean similarity for a downstream task)\n",
    "- Challenges for GNNs (over time):\n",
    "    - Heterogeneity:\n",
    "    - Scale: Big GNNs are really slow! Models get slower as they go deeper in the graph\n",
    "    - What kind of graph do we use?\n",
    "        - Given a partially labelled set of nodes, how do we predict things for the remaining nodes?\n",
    "        - Graph design problem: given a multi-modal feature space and partial labelling, can we learn an algorithm that will give us the right graph?\n",
    "        - Grale: scalable solution\n",
    "    - Generative/\n",
    "\n",
    "- Message passing allows flexibility:\n",
    "    - typically use custom message passing operation for each particular task\n",
    "    - TF-GNN: Tensor-flow GNN framework\n",
    "    \n",
    "- GraphWorld:\n",
    "    - Simulate millions of GNN task datasets\n",
    "    - Can be used to benchmark GNN tasks!\n",
    "    - Very nice to benchmark by just dropping an algorithm in\n",
    "    \n",
    "- Biased samples can really affect GNN performance\n",
    "- Shift-robust GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6482c09a",
   "metadata": {},
   "source": [
    "## Dynamic and Signed GNNs for Web Safety and Integrity - Applications to Bad Actor Detection on Social Media Platforms\n",
    "__Author:__ Srijan Kumar\n",
    "\n",
    "- 145M fake accounts on FB\n",
    "- $>$ 300M fake reviews on Amazon\n",
    "- They create dynamic GNNs for web safety and integrity\n",
    "- Temporal interaction networks: flexible way to represent time-evolving relations\n",
    "- Jodie: mutually-recursive RNN framework\n",
    "    - User RNN and Item RNN --> update component for 'users' and 'items'\n",
    "    - From Kalman filters: forecasting the embeddings\n",
    "- Model works already at facebook\n",
    "- Signed dynamic networks\n",
    "    - Signed networks: edges are positive or negative\n",
    "    - Very useful to detect things like conflict and toxicity\n",
    "- Prediction: signed links with GNNs\n",
    "    - SEMBA: balanced aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acdb17",
   "metadata": {},
   "source": [
    "## Graph Mining for Next-Generation Intelligent Assistants on AR/VR Devices\n",
    "__Author:__ Luna Dong (Meta)\n",
    "\n",
    "- Aim: Meta's assistant\n",
    "- Meta has Smart Glasses\n",
    "- Assistant goes from sound-only to multi-modal\n",
    "- ASR + CV --> GNN for integrating multi-modal information\n",
    "- They want to create a knowledge graph based on knowledge, behaviour and social behaviour!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ff6aa",
   "metadata": {},
   "source": [
    "## Graph Learning in NLP Applications\n",
    "__Author:__ Michi Yasunaga\n",
    "\n",
    "- Corpus is not a list of documents, but a __GRAPH__ of documents!\n",
    "- Knowledge graphs can capture lots of latent relations about entities\n",
    "- His aim is to create a language-knowledge model\n",
    "- Looked into LinkBERT and DRAGON models to combine them\n",
    "- All his papers and code are available online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e60b7e",
   "metadata": {},
   "source": [
    "AT THIS POINT I GOT TIRED AND STOPPED ATTENDING, ALMOST MIDNIGHT HERE :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b049845d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/home/joao/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      5\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      6\u001b[0m                            [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch_geometric/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleType\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_module\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch_geometric/data/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhetero_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HeteroData\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemporal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemporalData\n",
      "File \u001b[0;32m~/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch_geometric/data/data.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseTensor\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     FeatureStore,\n\u001b[1;32m     24\u001b[0m     FeatureTensorType,\n\u001b[1;32m     25\u001b[0m     TensorAttr,\n\u001b[1;32m     26\u001b[0m     _field_status,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     EDGE_LAYOUT_TO_ATTR_NAME,\n\u001b[1;32m     30\u001b[0m     EdgeAttr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     edge_tensor_type_to_adj_type,\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch_sparse/__init__.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch/_ops.py:255\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    250\u001b[0m path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ctypes/__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /home/joao/Desktop/GNN-Tutorial/env/lib/python3.8/site-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from time import time\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "Data(edge_index=[2, 4], x=[3, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
